{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facetorch import FaceAnalyzer\n",
    "from omegaconf import OmegaConf\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from typing import Dict\n",
    "import operator\n",
    "import torchvision\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_config = \"gpu.config.yml\" \n",
    "cfg = OmegaConf.load(path_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img_input = 'test.jpg'\n",
    "path_img_output = 'test_output.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2024-03-13 00:56:48,055\", \"levelname\": \"INFO\", \"message\": \"Initializing FaceAnalyzer\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:48,056\", \"levelname\": \"INFO\", \"message\": \"Initializing BaseReader\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:48,065\", \"levelname\": \"INFO\", \"message\": \"Initializing FaceDetector\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:48,348\", \"levelname\": \"INFO\", \"message\": \"Initializing FaceUnifier\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:48,357\", \"levelname\": \"INFO\", \"message\": \"Initializing FacePredictor objects\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:48,357\", \"levelname\": \"INFO\", \"message\": \"Initializing FacePredictor embed\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:48,639\", \"levelname\": \"INFO\", \"message\": \"Initializing FacePredictor verify\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:48,891\", \"levelname\": \"INFO\", \"message\": \"Initializing FacePredictor fer\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:49,152\", \"levelname\": \"INFO\", \"message\": \"Initializing FacePredictor au\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:49,445\", \"levelname\": \"INFO\", \"message\": \"Initializing FacePredictor va\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:49,727\", \"levelname\": \"INFO\", \"message\": \"Initializing FacePredictor deepfake\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:50,013\", \"levelname\": \"INFO\", \"message\": \"Initializing FacePredictor align\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:50,277\", \"levelname\": \"INFO\", \"message\": \"Initializing BaseUtilizer objects\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:50,277\", \"levelname\": \"INFO\", \"message\": \"Initializing BaseUtilizer align\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:50,313\", \"levelname\": \"INFO\", \"message\": \"Initializing BaseUtilizer draw_boxes\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:50,314\", \"levelname\": \"INFO\", \"message\": \"Initializing BaseUtilizer draw_landmarks\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:50,316\", \"levelname\": \"INFO\", \"message\": \"Running FaceAnalyzer\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:50,316\", \"levelname\": \"INFO\", \"message\": \"Reading image\", \"input\": \"test.jpg\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:50,354\", \"levelname\": \"INFO\", \"message\": \"Detecting faces\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:50,890\", \"levelname\": \"INFO\", \"message\": \"Number of faces: 4\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:50,890\", \"levelname\": \"INFO\", \"message\": \"Unifying faces\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:50,891\", \"levelname\": \"INFO\", \"message\": \"Predicting facial features\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:50,891\", \"levelname\": \"INFO\", \"message\": \"Running FacePredictor: embed\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:50,976\", \"levelname\": \"INFO\", \"message\": \"Running FacePredictor: verify\"}\n",
      "{\"asctime\": \"2024-03-13 00:56:51,066\", \"levelname\": \"INFO\", \"message\": \"Running FacePredictor: fer\"}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m FaceAnalyzer(cfg\u001b[38;5;241m.\u001b[39manalyzer)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# warmup\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_img_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfix_img_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfix_img_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_img_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_img_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\09350\\.conda\\envs\\myenv\\lib\\contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\09350\\.conda\\envs\\myenv\\lib\\site-packages\\facetorch\\analyzer\\core.py:170\u001b[0m, in \u001b[0;36mFaceAnalyzer.run\u001b[1;34m(self, image_source, path_image, batch_size, fix_img_size, return_img_data, include_tensors, path_output, tensor)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m predictor_name, predictor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictors\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning FacePredictor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictor_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 170\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_predict_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUtilizing facial features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m utilizer_name, utilizer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mutilizers\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\09350\\.conda\\envs\\myenv\\lib\\site-packages\\facetorch\\analyzer\\core.py:125\u001b[0m, in \u001b[0;36mFaceAnalyzer.run.<locals>._predict_batch\u001b[1;34m(data, predictor, predictor_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m     face_indx_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(face_indx_start \u001b[38;5;241m+\u001b[39m batch_size, n_faces)\n\u001b[0;32m    122\u001b[0m     face_batch_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[0;32m    123\u001b[0m         [face\u001b[38;5;241m.\u001b[39mtensor \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mfaces[face_indx_start:face_indx_end]]\n\u001b[0;32m    124\u001b[0m     )\n\u001b[1;32m--> 125\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_batch_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     data\u001b[38;5;241m.\u001b[39madd_preds(preds, predictor_name, face_indx_start)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\09350\\.conda\\envs\\myenv\\lib\\contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\09350\\.conda\\envs\\myenv\\lib\\site-packages\\facetorch\\analyzer\\predictor\\core.py:53\u001b[0m, in \u001b[0;36mFacePredictor.run\u001b[1;34m(self, faces)\u001b[0m\n\u001b[0;32m     51\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessor\u001b[38;5;241m.\u001b[39mrun(faces)\n\u001b[0;32m     52\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(faces)\n\u001b[1;32m---> 53\u001b[0m preds_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m preds_list\n",
      "File \u001b[1;32mc:\\Users\\09350\\.conda\\envs\\myenv\\lib\\contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\09350\\.conda\\envs\\myenv\\lib\\site-packages\\facetorch\\analyzer\\predictor\\post.py:115\u001b[0m, in \u001b[0;36mPostArgMax.run\u001b[1;34m(self, preds)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;129m@Timer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPostArgMax.run\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{name}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{milliseconds:.2f}\u001b[39;00m\u001b[38;5;124m ms\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger\u001b[38;5;241m=\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Prediction]:\n\u001b[0;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Post-processes the prediction tensor using argmax and returns a list of prediction data structures, one for each face.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m        List[Prediction]: List of prediction data structures containing the predicted labels and confidence scores for each face in the batch.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    116\u001b[0m     pred_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_pred_list(preds, indices)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred_list\n",
      "\u001b[1;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "analyzer = FaceAnalyzer(cfg.analyzer)\n",
    "\n",
    "# warmup\n",
    "response = analyzer.run(\n",
    "        path_image=path_img_input,\n",
    "        batch_size=cfg.batch_size,\n",
    "        fix_img_size=cfg.fix_img_size,\n",
    "        return_img_data=False,\n",
    "        include_tensors=True,\n",
    "        path_output=path_img_output,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"asctime\": \"2024-03-13 00:58:00,302\", \"levelname\": \"INFO\", \"message\": \"Running FaceAnalyzer\"}\n",
      "{\"asctime\": \"2024-03-13 00:58:00,304\", \"levelname\": \"INFO\", \"message\": \"Reading image\", \"input\": \"test.jpg\"}\n",
      "{\"asctime\": \"2024-03-13 00:58:00,345\", \"levelname\": \"INFO\", \"message\": \"Detecting faces\"}\n",
      "{\"asctime\": \"2024-03-13 00:58:04,782\", \"levelname\": \"INFO\", \"message\": \"Number of faces: 4\"}\n",
      "{\"asctime\": \"2024-03-13 00:58:04,783\", \"levelname\": \"INFO\", \"message\": \"Unifying faces\"}\n",
      "{\"asctime\": \"2024-03-13 00:58:04,785\", \"levelname\": \"INFO\", \"message\": \"Predicting facial features\"}\n",
      "{\"asctime\": \"2024-03-13 00:58:04,786\", \"levelname\": \"INFO\", \"message\": \"Running FacePredictor: embed\"}\n",
      "{\"asctime\": \"2024-03-13 00:58:09,011\", \"levelname\": \"INFO\", \"message\": \"Running FacePredictor: verify\"}\n",
      "{\"asctime\": \"2024-03-13 00:58:13,280\", \"levelname\": \"INFO\", \"message\": \"Running FacePredictor: fer\"}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_img_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfix_img_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfix_img_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_img_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_img_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_img_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\09350\\.conda\\envs\\myenv\\lib\\contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\09350\\.conda\\envs\\myenv\\lib\\site-packages\\facetorch\\analyzer\\core.py:170\u001b[0m, in \u001b[0;36mFaceAnalyzer.run\u001b[1;34m(self, image_source, path_image, batch_size, fix_img_size, return_img_data, include_tensors, path_output, tensor)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m predictor_name, predictor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictors\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning FacePredictor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictor_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 170\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_predict_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUtilizing facial features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m utilizer_name, utilizer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mutilizers\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\09350\\.conda\\envs\\myenv\\lib\\site-packages\\facetorch\\analyzer\\core.py:125\u001b[0m, in \u001b[0;36mFaceAnalyzer.run.<locals>._predict_batch\u001b[1;34m(data, predictor, predictor_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m     face_indx_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(face_indx_start \u001b[38;5;241m+\u001b[39m batch_size, n_faces)\n\u001b[0;32m    122\u001b[0m     face_batch_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[0;32m    123\u001b[0m         [face\u001b[38;5;241m.\u001b[39mtensor \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mfaces[face_indx_start:face_indx_end]]\n\u001b[0;32m    124\u001b[0m     )\n\u001b[1;32m--> 125\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_batch_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m     data\u001b[38;5;241m.\u001b[39madd_preds(preds, predictor_name, face_indx_start)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\09350\\.conda\\envs\\myenv\\lib\\contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\09350\\.conda\\envs\\myenv\\lib\\site-packages\\facetorch\\analyzer\\predictor\\core.py:53\u001b[0m, in \u001b[0;36mFacePredictor.run\u001b[1;34m(self, faces)\u001b[0m\n\u001b[0;32m     51\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessor\u001b[38;5;241m.\u001b[39mrun(faces)\n\u001b[0;32m     52\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(faces)\n\u001b[1;32m---> 53\u001b[0m preds_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m preds_list\n",
      "File \u001b[1;32mc:\\Users\\09350\\.conda\\envs\\myenv\\lib\\contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\09350\\.conda\\envs\\myenv\\lib\\site-packages\\facetorch\\analyzer\\predictor\\post.py:115\u001b[0m, in \u001b[0;36mPostArgMax.run\u001b[1;34m(self, preds)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;129m@Timer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPostArgMax.run\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{name}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{milliseconds:.2f}\u001b[39;00m\u001b[38;5;124m ms\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger\u001b[38;5;241m=\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Prediction]:\n\u001b[0;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Post-processes the prediction tensor using argmax and returns a list of prediction data structures, one for each face.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m        List[Prediction]: List of prediction data structures containing the predicted labels and confidence scores for each face in the batch.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    116\u001b[0m     pred_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_pred_list(preds, indices)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pred_list\n",
      "\u001b[1;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "response = analyzer.run(\n",
    "        path_image=path_img_input,\n",
    "        batch_size=cfg.batch_size,\n",
    "        fix_img_size=cfg.fix_img_size,\n",
    "        return_img_data=cfg.return_img_data,\n",
    "        include_tensors=cfg.include_tensors,\n",
    "        path_output=path_img_output,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
